# -*- coding: utf-8 -*-
"""Midterm Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IgqjvaYqqx_bFxHWYxtdBW4Q8KJZEhIG

# **PCA Project with Two dataset (Breast cancer & CIFAR10)**

# Call Libraries & Datasets
"""

# Commented out IPython magic to ensure Python compatibility.
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import to_categorical
from keras.optimizers import RMSprop
from tabulate import tabulate
from mpl_toolkits.mplot3d import Axes3D
#------------------------------------#
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

from sklearn.datasets import load_breast_cancer
from keras.datasets import cifar10

"""# Load Breast Cancer Dataset"""

# Load the Breast Cancer dataset
breast = load_breast_cancer()

# Extract the data and labels
breast_data = breast.data
breast_labels = breast.target

# Check the shapes of data and labels
print(breast_data.shape)
print(breast_labels.shape)

"""# Concatenate Data and Labels, Create DataFrame, and Replace Labels"""

# Reshape labels to match the data shape
labels = np.reshape(breast_labels,(569,1))

# Concatenate data and labels
final_breast_data = np.concatenate([breast_data,labels],axis=1)

final_breast_data.shape

# Create a DataFrame
breast_dataset = pd.DataFrame(final_breast_data)

# Add feature names as column headers
features = breast.feature_names
features_labels = np.append(features,'label')
breast_dataset.columns = features_labels

features

# Replace labels 0 and 1 with 'Benign' and 'Malignant'
breast_dataset['label'].replace(0, 'Benign',inplace=True)
breast_dataset['label'].replace(1, 'Malignant',inplace=True)

# Display the first few rows of the dataset
breast_dataset.head()

# Display the last few rows of the dataset
breast_dataset.tail()

"""# Load Cifar10 Dataset"""

# Load CIFAR-10 dataset
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Display shapes of training and testing data
print('Traning data shape:', x_train.shape)
print('Testing data shape:', x_test.shape)

# Shapes of labels
y_train.shape,y_test.shape

# Find unique classes in training labels
classes = np.unique(y_train)
nClasses = len(classes)
print('Total number of outputs : ', nClasses)
print('Output classes : ', classes)

# Dictionary for mapping class numbers to names
label_dict = {
 0: 'airplane',
 1: 'automobile',
 2: 'bird',
 3: 'cat',
 4: 'deer',
 5: 'dog',
 6: 'frog',
 7: 'horse',
 8: 'ship',
 9: 'truck',
}

"""# Display the first image in training data & in testng data"""

plt.figure(figsize=[5,5])

# Display the first image in training data
plt.subplot(121)
curr_img = np.reshape(x_train[0], (32,32,3))
plt.imshow(curr_img)
print(plt.title("(Label: " + str(label_dict[y_train[0][0]]) + ")"))

# Display the first image in testing data
plt.subplot(122)
curr_img = np.reshape(x_test[0],(32,32,3))
plt.imshow(curr_img)
print(plt.title("(Label: " + str(label_dict[y_test[0][0]]) + ")"))

"""# Normalizing the features"""

# Get the features and labels from the breast dataset
x = breast_dataset.loc[:, features].values

# normalizing the features
x = StandardScaler().fit_transform(x)

# Checking shape of normalized features
x.shape

# Checking mean and standard deviation after normalization
np.mean(x),np.std(x)

# Creating feature columns for the normalized data
feat_cols = ['feature'+str(i) for i in range(x.shape[1])]

# Creating a DataFrame for the normalized data
normalised_breast = pd.DataFrame(x,columns=feat_cols)

# Displaying the last few rows of the normalized breast dataset
normalised_breast.tail()

"""# **Two Components Breast Cancer Dataset & Plot**"""

# Perform PCA with 2 components
pca_breast2 = PCA(n_components = 2)
principalComponents_breast2 = pca_breast2.fit_transform(x)

# Create a DataFrame for the principal components
principal_breast_Df2 = pd.DataFrame(data = principalComponents_breast2
             , columns = ['principal component 1', 'principal component 2'])


# Print the last few rows
table2 = tabulate(principal_breast_Df2.tail(), headers='keys', tablefmt='pretty')
print(table2)

# Print explained variation per principal component
print('Explained variation per principal component: {}'.format(pca_breast2.explained_variance_ratio_))

# Plot the principal components for Breast Cancer Dataset (2 components)
plt.figure()
plt.figure(figsize=(10,10))
plt.xticks(fontsize=12)
plt.yticks(fontsize=14)
plt.xlabel('Principal Component - 1',fontsize=20)
plt.ylabel('Principal Component - 2',fontsize=20)
plt.title("Principal Component Analysis of Breast Cancer Dataset",fontsize=20)
targets = ['Benign', 'Malignant']
colors = ['r', 'g']
for target, color in zip(targets,colors):
    indicesToKeep = breast_dataset['label'] == target
    plt.scatter(principal_breast_Df2.loc[indicesToKeep, 'principal component 1']
               , principal_breast_Df2.loc[indicesToKeep, 'principal component 2'], c = color, s = 50)

plt.legend(targets,prop={'size': 15})

"""# **Three Components Breast Cancer Dataset & Plot**"""

# Perform PCA with 3 components
pca_breast3 = PCA(n_components = 3)
principalComponents_breast3 = pca_breast3.fit_transform(x)

# Create a DataFrame for the principal components
principal_breast_Df3 = pd.DataFrame(data = principalComponents_breast3
             , columns = ['principal component 1', 'principal component 2', 'principal component 3'])

# Print the last few rows
table3 = tabulate(principal_breast_Df3.tail(), headers='keys', tablefmt='pretty')
print(table3)

# Print explained variation per principal component
print('Explained variation per principal component: {}'.format(pca_breast3.explained_variance_ratio_))

# Create a 3D scatter plot
fig = plt.figure(figsize = (10, 10))
ax = fig.add_subplot(111, projection='3d')
ax.set_xlabel('Principal Component 1', fontsize = 15)
ax.set_ylabel('Principal Component 2', fontsize = 15)
ax.set_zlabel('Principal Component 3', fontsize = 15)
ax.set_title('3 Component PCA', fontsize = 20)

targets = ['Benign', 'Malignant']
colors = ['r', 'g']
for target, color in zip(targets,colors):
    indicesToKeep = breast_dataset['label'] == target
    ax.scatter(principal_breast_Df3.loc[indicesToKeep, 'principal component 1']
               , principal_breast_Df3.loc[indicesToKeep, 'principal component 2']
               , principal_breast_Df3.loc[indicesToKeep, 'principal component 3']
               , c = color
               , s = 50)
ax.legend(targets)
ax.grid()
plt.show()

"""# **Four Components Breast Cancer Dataset & Plot**"""

# Perform PCA with 4 components
pca_breast4 = PCA(n_components = 4)
principalComponents_breast4 = pca_breast4.fit_transform(x)

# Create a DataFrame for the principal components
principal_breast_Df4 = pd.DataFrame(data = principalComponents_breast4
             , columns = ['principal component 1', 'principal component 2', 'principal component 3', 'principal component 4'])

# Print the last few rows
table4 = tabulate(principal_breast_Df4.tail(), headers='keys', tablefmt='pretty')
print(table4)

# Print explained variation per principal component
print('Explained variation per principal component: {}'.format(pca_breast4.explained_variance_ratio_))

# Create a 3D scatter plot with color map for the fourth component
fig = plt.figure(figsize=(10, 10))
ax = fig.add_subplot(111, projection='3d')
ax.set_xlabel('Principal Component 1', fontsize=15)
ax.set_ylabel('Principal Component 2', fontsize=15)
ax.set_zlabel('Principal Component 3', fontsize=15)
ax.set_title('3 Component PCA with Color Map', fontsize=20)

# Scatter plot with color map based on the fourth component
scatter = ax.scatter(principal_breast_Df4['principal component 1'],
                     principal_breast_Df4['principal component 2'],
                     principal_breast_Df4['principal component 3'],
                     c=principal_breast_Df4['principal component 4'],
                     cmap='viridis')

# Add a color bar which maps values to colors
cbar = plt.colorbar(scatter)
cbar.set_label('Principal Component 4', fontsize=12)

plt.show()

"""# **Five Components Breast Cancer Dataset & Plot**"""

# Perform PCA with 5 components
pca_breast5 = PCA(n_components = 5)
principalComponents_breast5 = pca_breast5.fit_transform(x)

# Create a DataFrame for the principal components
principal_breast_Df5 = pd.DataFrame(data = principalComponents_breast5
             , columns = ['principal component 1', 'principal component 2', 'principal component 3', 'principal component 4', 'principal component 5'])

# Print the last few rows
table5 = tabulate(principal_breast_Df5.tail(), headers='keys', tablefmt='pretty')
print(table5)

# Print explained variation per principal component
print('Explained variation per principal component: {}'.format(pca_breast5.explained_variance_ratio_))


principal_breast_Df5 = pd.DataFrame(
    data=principalComponents_breast5,
    columns=[
        'principal component 1',
        'principal component 2',
        'principal component 3',
        'principal component 4',
        'principal component 5'
    ]
)

fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

# Plot all five components in a single 3D scatter plot
sc = ax.scatter(
    principal_breast_Df5['principal component 1'],
    principal_breast_Df5['principal component 2'],
    principal_breast_Df5['principal component 3'],
    c=principal_breast_Df5['principal component 4'],  # Color by PC4
    s=principal_breast_Df5['principal component 5']*100,  # Size by PC5
    cmap='viridis'
)

ax.set_xlabel('Principal Component 1')
ax.set_ylabel('Principal Component 2')
ax.set_zlabel('Principal Component 3')
ax.set_title('All Five Principal Components')

# Create a colorbar for the scatter plot
cbar = fig.colorbar(sc)
cbar.set_label('Principal Component 4', rotation=270, labelpad=20)

plt.show()

"""# Explained Variance Ratio for Principal Components (2 - 5)"""

plt.figure()
plt.bar(range(1, pca_breast2.n_components_ + 1), pca_breast2.explained_variance_ratio_)
plt.xlabel('Principal Component')
plt.ylabel('Explained Variance Ratio')
plt.title('Explained Variance Ratio for Principal Components (2)')
plt.show()

plt.figure()
plt.bar(range(1, pca_breast3.n_components_ + 1), pca_breast3.explained_variance_ratio_)
plt.xlabel('Principal Component')
plt.ylabel('Explained Variance Ratio')
plt.title('Explained Variance Ratio for Principal Components (3)')
plt.show()

plt.figure()
plt.bar(range(1, pca_breast4.n_components_ + 1), pca_breast4.explained_variance_ratio_)
plt.xlabel('Principal Component')
plt.ylabel('Explained Variance Ratio')
plt.title('Explained Variance Ratio for Principal Components (4)')
plt.show()

plt.figure()
plt.bar(range(1, pca_breast5.n_components_ + 1), pca_breast5.explained_variance_ratio_)
plt.xlabel('Principal Component')
plt.ylabel('Explained Variance Ratio')
plt.title('Explained Variance Ratio for Principal Components (5)')
plt.show()

# Data for plotting
num_components = [pca_breast2.n_components_, pca_breast3.n_components_, pca_breast4.n_components_, pca_breast5.n_components_]
explained_variance_ratios = [pca_breast2.explained_variance_ratio_, pca_breast3.explained_variance_ratio_,
    pca_breast4.explained_variance_ratio_,
    pca_breast5.explained_variance_ratio_
]

# Flatten the data for plotting
x_data = []
y_data = []
for i, ratios in enumerate(explained_variance_ratios):
    x_data.extend([num_components[i]] * len(ratios))
    y_data.extend(ratios)

# Plotting
plt.figure()
plt.scatter(x_data, y_data, s=100, c='b', alpha=0.7)
plt.xlabel('Number of Principal Components')
plt.ylabel('Explained Variance Ratio')
plt.title('Explained Variance Ratio for Different Number of Components')
plt.grid(True)
plt.show()

"""# Percentage of Information Lost for Principal Components (2 - 5)"""

plt.figure()
plt.bar(range(1, pca_breast2.n_components_ + 1), (1 - pca_breast2.explained_variance_ratio_))
plt.xlabel('Principal Component')
plt.ylabel('Percentage of Information Lost')
plt.title('Percentage of Information Lost for Principal Components')
plt.show()

plt.figure()
plt.bar(range(1, pca_breast3.n_components_ + 1), (1 - pca_breast3.explained_variance_ratio_))
plt.xlabel('Principal Component')
plt.ylabel('Percentage of Information Lost')
plt.title('Percentage of Information Lost for Principal Components')
plt.show()

plt.figure()
plt.bar(range(1, pca_breast4.n_components_ + 1), (1 - pca_breast4.explained_variance_ratio_))
plt.xlabel('Principal Component')
plt.ylabel('Percentage of Information Lost')
plt.title('Percentage of Information Lost for Principal Components')
plt.show()

plt.figure()
plt.bar(range(1, pca_breast5.n_components_ + 1), (1 - pca_breast5.explained_variance_ratio_))
plt.xlabel('Principal Component')
plt.ylabel('Percentage of Information Lost')
plt.title('Percentage of Information Lost for Principal Components')
plt.show()

# Data for plotting
num_components = [pca_breast2.n_components_, pca_breast3.n_components_, pca_breast4.n_components_, pca_breast5.n_components_]
explained_variance_ratios = [pca_breast2.explained_variance_ratio_, pca_breast3.explained_variance_ratio_,
    pca_breast4.explained_variance_ratio_,
    pca_breast5.explained_variance_ratio_
]

# Calculate percentage of information lost
information_lost = [(1 - ratios) * 100 for ratios in explained_variance_ratios]

# Flatten the data for plotting
x_data = []
y_data_lost = []
for i, ratios in enumerate(explained_variance_ratios):
    x_data.extend([num_components[i]] * len(ratios))
    y_data_lost.extend(information_lost[i])

# Plotting
plt.figure(figsize=(10, 6))

# Plot Percentage of Information Lost
plt.scatter(x_data, y_data_lost, s=100, c='r', alpha=0.7, label='Percentage of Information Lost')

plt.xlabel('Number of Principal Components')
plt.ylabel('Percentage of Information Lost')
plt.title('Percentage of Information Lost for Different Number of Components')
plt.legend()
plt.grid(True)
plt.show()

"""# Explained Variance Ratio and Information Loss Analysis (breast Cancer)"""

# Data for plotting
num_components = [pca_breast2.n_components_, pca_breast3.n_components_, pca_breast4.n_components_, pca_breast5.n_components_]
explained_variance_ratios = [pca_breast2.explained_variance_ratio_, pca_breast3.explained_variance_ratio_,
    pca_breast4.explained_variance_ratio_,
    pca_breast5.explained_variance_ratio_
]

# Calculate percentage of information lost
information_lost = [(1 - ratios) * 100 for ratios in explained_variance_ratios]

# Flatten the data for plotting
x_data = []
y_data_ratio = []
y_data_lost = []
for i, ratios in enumerate(explained_variance_ratios):
    x_data.extend([num_components[i]] * len(ratios))
    y_data_ratio.extend(ratios)
    y_data_lost.extend(information_lost[i])

# Plotting
fig, ax1 = plt.subplots(figsize=(16, 9))

# Scatter plot for Explained Variance Ratio
ax1.scatter(x_data, y_data_ratio, s=100, c='b', alpha=0.7, label='Explained Variance Ratio')
ax1.set_xlabel('Number of Principal Components')
ax1.set_ylabel('Explained Variance Ratio', color='b')
ax1.tick_params(axis='y', labelcolor='b')
ax1.grid(True)

# Create a second y-axis for Percentage of Information Lost
ax2 = ax1.twinx()
ax2.scatter(x_data, y_data_lost, s=25, c='r', alpha=0.7, label='Percentage of Information Lost')
ax2.set_ylabel('Percentage of Information Lost', color='r')
ax2.tick_params(axis='y', labelcolor='r')

# Add legends and title
plt.title('Explained Variance Ratio vs. Percentage of Information Lost')
fig.tight_layout()
fig.legend(loc='upper right', bbox_to_anchor=(0.9, 0.9))

plt.show()

"""# **Preprocessing CIFAR-10 Dataset**"""

# Normalize the pixel values between 0 and 1
x_train = x_train/255.0

# Check the minimum and maximum values after normalization
print('Minimum and Maximum values after normalization are (', np.min(x_train), ') and (', np.max(x_train), ')')

# Check the shape of the training data
print('The shape of the training data are', x_train.shape)

# Flatten the 32x32x3 images into a single vector of length 3072
x_train_flat = x_train.reshape(-1,3072)

# Create feature column names for the DataFrame
feat_cols = ['pixel'+str(i) for i in range(x_train_flat.shape[1])]

# Create a DataFrame for the flattened training data
df_cifar = pd.DataFrame(x_train_flat,columns=feat_cols)

# Add the labels to the DataFrame, where 'y_train' contains the class labels
df_cifar['label'] = y_train
print('The size of the dataframe: {}'.format(df_cifar.shape))

# Display the first few rows of the DataFrame
df_cifar.head()

"""# **Two Components (Cifar-10 Dataset) & Plot**"""

# Apply PCA with 2 components
pca_cifar2 = PCA(n_components = 2)
principalComponents_cifar2 = pca_cifar2.fit_transform(df_cifar.iloc[:,:-1])

# Create a DataFrame to hold the transformed components
principal_cifar_Df2 = pd.DataFrame(data = principalComponents_cifar2
             , columns = ['principal component 1', 'principal component 2'])
principal_cifar_Df2['y'] = y_train

# Displaying principal_cifar_Df2.head() as a table
table_cifar2 = tabulate(principal_cifar_Df2.head(), headers='keys', tablefmt='pretty')
print("First few rows of Principal Components (2 components) for Cifar10 Dataset:\n")
print(table_cifar2)

# Display the explained variance ratio for the two components
print('Explained variation per principal component: {}'.format(pca_cifar2.explained_variance_ratio_))

plt.figure(figsize=(16,10))
sns.scatterplot(
    x="principal component 1", y="principal component 2",
    hue="y",
    palette=sns.color_palette("hls", 10),
    data=principal_cifar_Df2,
    legend="full",
    alpha=0.3
)

"""# **Three Components (Cifar-10 Dataset) & Plot**"""

# Apply PCA with 3 components
pca_cifar3 = PCA(n_components=3)
principalComponents_cifar3 = pca_cifar3.fit_transform(df_cifar.iloc[:,:-1])

# Create a DataFrame to hold the transformed components
principal_cifar_Df3 = pd.DataFrame(data=principalComponents_cifar3,
                                   columns=['principal component 1', 'principal component 2', 'principal component 3'])
principal_cifar_Df3['y'] = y_train

# Displaying principal_cifar_Df3.head() as a table
table_cifar3 = tabulate(principal_cifar_Df3.head(), headers='keys', tablefmt='pretty')
print("First few rows of Principal Components (3 components) for Cifar10 Dataset:\n")
print(table_cifar3)

# Display the explained variance ratio for the three components
print('Explained variation per principal component: {}'.format(pca_cifar3.explained_variance_ratio_))

# Create a figure for the plot
plt.figure(figsize=(22, 12))
ax = plt.axes(projection='3d')

# Scatter plot for 3D visualization with legend
for label in np.unique(principal_cifar_Df3['y']):
    indices = principal_cifar_Df3['y'] == label
    ax.scatter3D(principal_cifar_Df3.loc[indices, 'principal component 1'],
                 principal_cifar_Df3.loc[indices, 'principal component 2'],
                 principal_cifar_Df3.loc[indices, 'principal component 3'],
                 label=label)

# Adding labels and title
ax.set_xlabel('Principal Component 1')
ax.set_ylabel('Principal Component 2')
ax.set_zlabel('Principal Component 3')
ax.set_title('3D Scatter Plot of Principal Components for CIFAR-10 Dataset')
ax.legend()

# Show the plot
plt.show()

"""# **Four Components (Cifar-10 Dataset) & Plot**"""

# Apply PCA with 4 components
pca_cifar4 = PCA(n_components = 4)
principalComponents_cifar4 = pca_cifar4.fit_transform(df_cifar.iloc[:,:-1])

# Create a DataFrame to hold the transformed components
principal_cifar_Df4 = pd.DataFrame(data = principalComponents_cifar4
             , columns = ['principal component 1', 'principal component 2', 'principal component 3', 'principal component 4'])
principal_cifar_Df4['y'] = y_train

# Displaying principal_cifar_Df4.head() as a table
table_cifar4 = tabulate(principal_cifar_Df4.head(), headers='keys', tablefmt='pretty')
print("First few rows of Principal Components (4 components) for Cifar10 Dataset:\n")
print(table_cifar4)

# Display the explained variance ratio for the four components
print('Explained variation per principal component: {}'.format(pca_cifar4.explained_variance_ratio_))

plt.figure(figsize=(12, 8))
ax = plt.axes(projection='3d')

# Scatter plot for 3D visualization with color based on 4th component
scatter = ax.scatter3D(principal_cifar_Df4['principal component 1'],
                       principal_cifar_Df4['principal component 2'],
                       principal_cifar_Df4['principal component 3'],
                       c=principal_cifar_Df4['principal component 4'],  # Color based on 4th component
                       cmap='hsv',
                       alpha=0.6)

# Adding labels and title
ax.set_xlabel('Principal Component 1')
ax.set_ylabel('Principal Component 2')
ax.set_zlabel('Principal Component 3')
ax.set_title('4D Scatter Plot with Color for Principal Component 4 (CIFAR-10 Dataset)')

# Adding a color bar for the 4th component
plt.colorbar(scatter, label='Principal Component 4')

# Show the plot
plt.show()

"""# **Five Components (Cifar-10 Dataset) & Plot**"""

# Apply PCA with 5 components
pca_cifar5 = PCA(n_components = 5)
principalComponents_cifar5 = pca_cifar5.fit_transform(df_cifar.iloc[:,:-1])

# Create a DataFrame to hold the transformed components
principal_cifar_Df5 = pd.DataFrame(data = principalComponents_cifar5
             , columns = ['principal component 1', 'principal component 2', 'principal component 3', 'principal component 4', 'principal component 5'])
principal_cifar_Df5['y'] = y_train

# Displaying principal_cifar_Df5.head() as a table
table_cifar5 = tabulate(principal_cifar_Df5.head(), headers='keys', tablefmt='pretty')
print("First few rows of Principal Components (5 components) for Cifar10 Dataset:\n")
print(table_cifar5)

# Display the explained variance ratio for the five components
print('Explained variation per principal component: {}'.format(pca_cifar5.explained_variance_ratio_))

# Create a 3D scatter plot
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

# Plot all five components in a single 3D scatter plot
sc = ax.scatter(
    principal_cifar_Df5['principal component 1'],
    principal_cifar_Df5['principal component 2'],
    principal_cifar_Df5['principal component 3'],
    c=principal_cifar_Df5['principal component 4'],  # Color by PC4
    s=principal_cifar_Df5['principal component 5'] * 100,  # Size by PC5
    cmap='viridis'
)

ax.set_xlabel('Principal Component 1')
ax.set_ylabel('Principal Component 2')
ax.set_zlabel('Principal Component 3')
ax.set_title('3D Scatter Plot with Color and Size by Principal Components')

# Create a colorbar for the scatter plot
cbar = fig.colorbar(sc)
cbar.set_label('Principal Component 4', rotation=270, labelpad=20)

plt.show()

"""# Explained Variance Ratio for Principal Components (2 - 5)"""

plt.figure(figsize=(10,5))
plt.bar(range(1, pca_cifar2.n_components_ + 1), pca_cifar2.explained_variance_ratio_)
plt.xlabel('Principal Component')
plt.ylabel('Explained Variance Ratio')
plt.title('Explained Variance Ratio for Principal Components')
plt.show()

plt.figure(figsize=(10,5))
plt.bar(range(1, pca_cifar3.n_components_ + 1), pca_cifar3.explained_variance_ratio_)
plt.xlabel('Principal Component')
plt.ylabel('Explained Variance Ratio')
plt.title('Explained Variance Ratio for Principal Components')
plt.show()

plt.figure(figsize=(10,5))
plt.bar(range(1, pca_cifar4.n_components_ + 1), pca_cifar4.explained_variance_ratio_)
plt.xlabel('Principal Component')
plt.ylabel('Explained Variance Ratio')
plt.title('Explained Variance Ratio for Principal Components')
plt.show()

plt.figure(figsize=(10,5))
plt.bar(range(1, pca_cifar5.n_components_ + 1), pca_cifar5.explained_variance_ratio_)
plt.xlabel('Principal Component')
plt.ylabel('Explained Variance Ratio')
plt.title('Explained Variance Ratio for Principal Components')
plt.show()

"""# Percentage of Information Lost for Principal Components (2 - 5)"""

plt.figure(figsize=(10,5))
plt.bar(range(1, pca_cifar2.n_components_ + 1), (1 - pca_cifar2.explained_variance_ratio_))
plt.xlabel('Principal Component')
plt.ylabel('Percentage of Information Lost')
plt.title('Percentage of Information Lost for Principal Components')
plt.show()

plt.figure(figsize=(10,5))
plt.bar(range(1, pca_cifar3.n_components_ + 1), (1 - pca_cifar3.explained_variance_ratio_))
plt.xlabel('Principal Component')
plt.ylabel('Percentage of Information Lost')
plt.title('Percentage of Information Lost for Principal Components')
plt.show()

plt.figure(figsize=(10,5))
plt.bar(range(1, pca_cifar4.n_components_ + 1), (1 - pca_cifar4.explained_variance_ratio_))
plt.xlabel('Principal Component')
plt.ylabel('Percentage of Information Lost')
plt.title('Percentage of Information Lost for Principal Components')
plt.show()

plt.figure(figsize=(10,5))
plt.bar(range(1, pca_cifar5.n_components_ + 1), (1 - pca_cifar5.explained_variance_ratio_))
plt.xlabel('Principal Component')
plt.ylabel('Percentage of Information Lost')
plt.title('Percentage of Information Lost for Principal Components')
plt.show()

"""# Explained Variance Ratio and Information Loss Analysis (CIFAR-10)"""

# Data for plotting
num_components_cifar = [pca_cifar2.n_components_, pca_cifar3.n_components_, pca_cifar4.n_components_, pca_cifar5.n_components_]
explained_variance_ratios_cifar = [pca_cifar2.explained_variance_ratio_, pca_cifar3.explained_variance_ratio_,
    pca_cifar4.explained_variance_ratio_,
    pca_cifar5.explained_variance_ratio_
]

# Calculate percentage of information lost
information_lost_cifar = [(1 - ratios) * 100 for ratios in explained_variance_ratios_cifar]

# Flatten the data for plotting
x_data_cifar = []
y_data_ratio_cifar = []
y_data_lost_cifar = []
for i, ratios in enumerate(explained_variance_ratios_cifar):
    x_data_cifar.extend([num_components_cifar[i]] * len(ratios))
    y_data_ratio_cifar.extend(ratios)
    y_data_lost_cifar.extend(information_lost_cifar[i])

# Plotting
fig, ax1_cifar = plt.subplots(figsize=(16, 9))

# Scatter plot for Explained Variance Ratio
ax1_cifar.scatter(x_data_cifar, y_data_ratio_cifar, s=100, c='b', alpha=0.7, label='Explained Variance Ratio')
ax1_cifar.set_xlabel('Number of Principal Components')
ax1_cifar.set_ylabel('Explained Variance Ratio', color='b')
ax1_cifar.tick_params(axis='y', labelcolor='b')
ax1_cifar.grid(True)

# Create a second y-axis for Percentage of Information Lost
ax2_cifar = ax1_cifar.twinx()
ax2_cifar.scatter(x_data_cifar, y_data_lost_cifar, s=25, c='r', alpha=0.7, label='Percentage of Information Lost')
ax2_cifar.set_ylabel('Percentage of Information Lost', color='r')
ax2_cifar.tick_params(axis='y', labelcolor='r')

# Add legends and title
plt.title('Explained Variance Ratio vs. Percentage of Information Lost for CIFAR-10 Dataset')
fig.tight_layout()
fig.legend(loc='upper right', bbox_to_anchor=(0.9, 0.9))

plt.show()

"""# **Setup Training model**"""

# Normalize the test data and reshape for model compatibility
x_test = x_test/255.0
x_test = x_test.reshape(-1,32,32,3)
x_test_flat = x_test.reshape(-1,3072)

PCA(copy=True, iterated_power='auto', random_state=None, svd_solver='auto', tol=0.0, whiten=False)

# Convert labels to categorical for model training
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# Set parameters for model training
batch_size = 128
epochs = 20

# Define the number of classes for the model
num_classes = 10

print(y_train.shape)
print(y_test.shape )

"""# **Training the model Without Speeding up the ML**"""

# Define the model architecture without PCA
model = Sequential()
model.add(Dense(1024, activation='relu', input_shape=(3072,)))
model.add(Dense(1024, activation='relu'))
model.add(Dense(512, activation='relu'))
model.add(Dense(256, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))

# Compile the model
model.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(),
              metrics=['accuracy'])

# Train the model
history = model.fit(x_train_flat, y_train,batch_size=batch_size,epochs=epochs,verbose=1,
                    validation_data=(x_test_flat, y_test))

"""# **Training the model With Speeding up the ML**

# PCA hold 90% of the variance
"""

# Apply PCA with 90% variance
pca9 = PCA(0.9)
pca9.fit(x_train_flat)

# Transform the training and test data
train_img_pca9 = pca9.transform(x_train_flat)
test_img_pca9 = pca9.transform(x_test_flat)

model9 = Sequential()
model9.add(Dense(1024, activation='relu', input_shape=(pca9.n_components_,)))
model9.add(Dense(1024, activation='relu'))
model9.add(Dense(512, activation='relu'))
model9.add(Dense(256, activation='relu'))
model9.add(Dense(num_classes, activation='softmax'))

# Display model summary
print("Input Shape is:", pca9.n_components_)
model9.summary()

# Compile the model with 90% variance
model9.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(),
              metrics=['accuracy'])

# Train the model with 90% variance
history9 = model9.fit(train_img_pca9, y_train,batch_size=batch_size,epochs=epochs,verbose=1, validation_data=(test_img_pca9, y_test))

"""# PCA hold 80% of the variance"""

# Apply PCA with 80% variance
pca8 = PCA(0.8)
pca8.fit(x_train_flat)

# Transform the training and test data
train_img_pca8 = pca8.transform(x_train_flat)
test_img_pca8 = pca8.transform(x_test_flat)

# Define the model architecture with 80% variance
model8 = Sequential()
model8.add(Dense(1024, activation='relu', input_shape=(pca8.n_components_,)))
model8.add(Dense(1024, activation='relu'))
model8.add(Dense(512, activation='relu'))
model8.add(Dense(256, activation='relu'))
model8.add(Dense(num_classes, activation='softmax'))

# Display model summary
print("Input Shape is:", pca8.n_components_)
model8.summary()

# Compile the model with 80% variance
model8.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(),
              metrics=['accuracy'])

# Train the model with 80% variance
history8 = model8.fit(train_img_pca8, y_train,batch_size=batch_size,epochs=epochs,verbose=1, validation_data=(test_img_pca8, y_test))

"""# PCA hold 70% of the variance"""

# Apply PCA with 70% variance
pca7 = PCA(0.7)
pca7.fit(x_train_flat)

# Transform the training and test data
train_img_pca7 = pca7.transform(x_train_flat)
test_img_pca7 = pca7.transform(x_test_flat)

# Define the model architecture with 70% variance
model7 = Sequential()
model7.add(Dense(1024, activation='relu', input_shape=(pca7.n_components_,)))
model7.add(Dense(1024, activation='relu'))
model7.add(Dense(512, activation='relu'))
model7.add(Dense(256, activation='relu'))
model7.add(Dense(num_classes, activation='softmax'))

# Display model summary
print("Input Shape is:", pca7.n_components_)
model7.summary()

# Compile the model with 70% variance
model7.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(),
              metrics=['accuracy'])

# Train the model with 70% variance
history7 = model7.fit(train_img_pca7, y_train,batch_size=batch_size,epochs=epochs,verbose=1, validation_data=(test_img_pca7, y_test))

"""# PCA hold 60% of the variance"""

# Apply PCA with 60% variance
pca6 = PCA(0.6)
pca6.fit(x_train_flat)

# Transform the training and test data
train_img_pca6 = pca6.transform(x_train_flat)
test_img_pca6 = pca6.transform(x_test_flat)

# Define the model architecture with 60% variance
model6 = Sequential()
model6.add(Dense(1024, activation='relu', input_shape=(pca6.n_components_,)))
model6.add(Dense(1024, activation='relu'))
model6.add(Dense(512, activation='relu'))
model6.add(Dense(256, activation='relu'))
model6.add(Dense(num_classes, activation='softmax'))

# Display model summary
print("Input Shape is:", pca6.n_components_)
model6.summary()

# Compile the model with 60% variance
model6.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(),
              metrics=['accuracy'])

# Train the model with 60% variance
history6 = model6.fit(train_img_pca6, y_train,batch_size=batch_size,epochs=epochs,verbose=1, validation_data=(test_img_pca6, y_test))

"""# PCA hold 50% of the variance"""

# Apply PCA with 50% variance
pca5 = PCA(0.5)
pca5.fit(x_train_flat)

# Transform the training and test data
train_img_pca5 = pca5.transform(x_train_flat)
test_img_pca5 = pca5.transform(x_test_flat)

# Define the model architecture with 50% variance
model5 = Sequential()
model5.add(Dense(1024, activation='relu', input_shape=(pca5.n_components_,)))
model5.add(Dense(1024, activation='relu'))
model5.add(Dense(512, activation='relu'))
model5.add(Dense(256, activation='relu'))
model5.add(Dense(num_classes, activation='softmax'))

# Display model summary
print("Input Shape is:", pca5.n_components_)
model5.summary()

# Compile the model with 50% variance
model5.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(),
              metrics=['accuracy'])

# Train the model with 50% variance
history5 = model5.fit(train_img_pca5, y_train,batch_size=batch_size,epochs=epochs,verbose=1, validation_data=(test_img_pca5, y_test))

"""# Explained Variance Ratio vs. Number of Principal Components"""

# Gather PCA objects and their explained variance ratios
pca_variances = [pca9, pca8, pca7, pca6, pca5]
pca_n_components = [pca.n_components_ for pca in pca_variances]
explained_variance_ratios = [pca.explained_variance_ratio_.sum() for pca in pca_variances]

# Plot the Explained Variance Ratio vs. Number of Principal Components
plt.figure(figsize=(10, 6))
plt.plot(pca_n_components, explained_variance_ratios, 'p-', markersize=12)
plt.xlabel('Number of Principal Components')
plt.ylabel('Explained Variance Ratio')
plt.title('Explained Variance Ratio vs. Number of Principal Components')

# Adding text annotations for each point
for i, txt in enumerate(explained_variance_ratios):
    if i == len(pca_n_components) - 1 or i == len(pca_n_components) -2:  # Check if it's the last point
        plt.text(pca_n_components[i] + 2.25, + 0.004 + explained_variance_ratios[i], f'{pca_n_components[i]}', ha='center', va='top', fontsize=10)
    else:
        plt.text(pca_n_components[i], -0.015 + explained_variance_ratios[i], f'{pca_n_components[i]}', ha='center', va='top', fontsize=10)

plt.show()

"""# Model Performance with Different PCA Configurations"""

import matplotlib.pyplot as plt

# Data for plotting
cases = ['5 Com No PCA', '2 Com PCA(90%)', '2 Com PCA(80%)', '2 Com PCA(70%)', '2 Com PCA(60%)', '2 Com PCA(50%)',
         '3 Com PCA(90%)', '3 Com PCA(80%)', '3 Com PCA(70%)', '3 Com PCA(60%)', '3 Com PCA(50%)',
         '4 Com PCA(90%)', '4 Com PCA(80%)', '4 Com PCA(70%)', '4 Com PCA(60%)', '4 Com PCA(50%)',
         '5 Com PCA(90%)', '5 Com PCA(80%)', '5 Com PCA(70%)', '5 Com PCA(60%)', '5 Com PCA(50%)']

accuracy = [51, 83, 77, 61, 40.648, 28, 83, 77, 61, 41, 28,
            83, 77, 61, 41, 28, 83, 77, 61, 41, 28]
val_accuracy = [45, 55, 50, 42, 35.3455, 28, 54, 50, 42, 35.525, 28,
                55, 51, 42, 35.525, 28, 54, 50, 42, 35, 28]
time_per_epoch = [41.53, 22.05, 20.40, 20.05, 20.2, 20.45,
                  21.35, 21.10, 20.40, 20.55, 20.80,
                  21.85, 20.85, 20.75, 21.3, 20.75,
                  21.20, 20.70, 20.50, 20.70, 20.55]
loss = [13.8, 4.8, 6.5, 10.8, 16.4, 19.9, 4.8, 6.5, 10.7, 16.4, 19.9,
        4.8, 6.6, 10.7, 16.4, 19.9, 4.8, 6.5, 10.7, 16.4, 19.9]
val_loss = [16.1, 24.6, 24.7, 21.9, 18.5, 20.1, 23.7, 24.4, 21.6, 18.6, 20,
            23.7, 24.4, 21.8, 18.5, 20.1, 23.7, 24.4, 21.6, 18.6, 20]


# Plotting
plt.figure(figsize=(12, 8))

# Plot lines for accuracy and validation accuracy
plt.plot(cases, accuracy, marker='o', label='Accuracy')
plt.plot(cases, val_accuracy, marker='s', label='Validation Accuracy')

# Plot lines for time and loss
plt.plot(cases, time_per_epoch, marker='x', label='Time per Epoch (s)')
plt.plot(cases, loss, marker='^', label='Loss')
plt.plot(cases, val_loss, marker='D', label='Validation Loss')

# Add labels and title
plt.xlabel('Cases')
plt.ylabel('Metrics')
plt.title('Model Performance with Different PCA Configurations')
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

